<!doctype html>
<!-- Machine GitHub pages theme was designed and developed by Jon Rohan, on Feb 7, 2012. -->
<!-- Follow him for fun. http://twitter.com/jonrohan. Tail his code on https://github.com/jonrohan -->
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <link rel="stylesheet" href="stylesheets/stylesheet.css" media="screen">
  <link rel="stylesheet" href="stylesheets/github-dark.css">
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
  <script type="text/javascript" src="javascripts/script.js"></script>

  <title>Cs4641-group39.GitHub.io</title>
  <meta name="description" content="CS 4641 Machine Learning Project">

  <meta name="viewport" content="width=device-width,initial-scale=1">

</head>

<body>

  <div class="wrapper">
    <header>
      <h1 class="title">CT Scan COVID Diagnosis</h1>
    </header>
    <div id="container">
      <p class="tagline">CS 4641 Fall 2020: Team 39's Machine Learning Project</p>
      <div id="main" role="main">
        <div class="download-bar">
        <div class="inner">
          <a href="https://github.gatech.edu/aazmi6/CS4641-Group39.github.io" class="code">View Cs4641-group39.GitHub.io on GitHub</a>
        </div>
        <span class="blc"></span><span class="trc"></span>
        </div>
        <article class="markdown-body">
          <h3>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h3>
<img src="summary.png" alt="Summary">
<h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>
<p>Our goal is to create a model that will learn from the lung CT scan dataset to determine whether or not new patients 
  are at risk for pneumonia as a result of being COVID-19 positive. With the new knowledge surrounding the virus, it 
  becomes much more crucial that patients seek special attention if the virus has infected the lungs. With this model, 
  doctors only need to upload the CT scan from the patient and the model will give vital, potentially life-saving information 
  on the next step of treatment.
</p>
<h3>
<a id="methods" class="anchor" href="#methods" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Methods</h3>
<p>We plan to use lung CT Scans provided on kaggle to determine whether a patient has COVID-19. We’re also planning to use a 
  CNN-based model through Pytorch in order to train our model to identify COVID-19 through CT lung scans.
</p>
<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h3>
<p>Given a set of lung images (some patients positive for Covid-19, some patients exposed to other conditions such as pneumonia, 
  and some healthy patients) our model will determine (to some % of confidence) whether or not a given patient's CT lung scan is 
  Covid positive.
</p>
<h3>
<a id="discussion" class="anchor" href="#discussion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Discussion</h3>
<p>The significance of this relates back to the ease with which doctors will be able to rapidly confirm patients’ condition, and 
  subsequently be able to use this information for deciding which route to take with treatment. This will be especially 
  significant for at-risk patients if the CT scan can reveal the results faster than a mouth or nose swab test.
</p>

<h2><a id="unsupervised" class="anchor" href="#unsupervised_learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unsupervised Learning</h2>

<h3>
  <a id="introduction" class="anchor" href="#PCA" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>PCA</h3>
  <p>
    PCA allows us to remove features in our data that contribute the least to the variance in the data. This can 
    help quicken the training of our supervised models. In addition, it can reveal the most significant 
    features within our data. Here is an example of applying PCA to a CT scan image:
  </p>
  <center><h5>Applying PCA (Negative Patient)</h5></center>
        <center><img src="images/pca.JPG" alt="PCA"  height="285" width="800"></center>
  <p>
    PCA was successfully implemented, but no use cases have been explored yet. We are potentially 
    considering using it for our CNN, which will be implemented in the near future for supervised learning. For most 
    test cases, 99% of variance was able to be recovered while dropping a majority of the components. This indicates 
    that we can apply PCA to reduce the number of components to be analyzed; as a result, fewer computations have to 
    be made to still yield an accurate model. <br><br>

    We can make some observations from the PCA result however. We can immediately tell that important features look 
    like white spaces within the lung scan. It could be picking up on ground glass opacities, which are white-ish/hazy 
    areas indicitive of illness in the lung. We will talk more about ground glass opacity in the next few sections.
  </p>
<h3>
  <a id="introduction" class="anchor" href="#CAM" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CAM</h3>
  <p>
    Class Activation Maps highlight the parts of the image that the Neural Network focuses on so we can 
    better understand how our neural network works in supervised learning when we reach that stage. 
    CAMs gives us an idea of what part of the data has to be focused on by building a heat map. We pasted
    this outputted heat map over our original image to understand important visual features.
    <br> When we worked with The VGG16 architecture, the output seemed to focus more on the heart area than the 
    rest of the lung scan. The model also didn’t have the best accuracy.</p>
          <center><img src="images/VGG16.png" alt="VGG16" height="400" width="200"></center>
  <p>
    When we worked with The resnet architecture, our output highlighted the ground glass opacity in the lungs 
    with a much better accuracy.
  </p>
          <center><img src="images/resnet.png" alt="resnet" height="400" width="200"></center>
  <p>In conclusion, the CAM model tells us that ground glass opacity and the heart are possibly important features, 
    a trend we observe with GMM and DBSCAN as well.</p>
<h3>
  <a id="DBSCAN" class="anchor" href="#DBSCAN" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>DBSCAN</h3>
  <p>DBSCAN is probably not the best way to go for image segmentation because the epsilon parameter is too 
    sensitive and would need to take time to find the perfect value to segment properly. Each image that 
    we ran through DBSCAN needed a drastically different epsilon in order to show results. Even though 
    the resulting images are interesting and helped us realize that there are differences between 
    COVID-positive and negative, it’s not the best to reduce noise and portions of the images. 
    Some additional understandings that we found through DBSCAN on the other hand was that many of the CT 
    scans clustered the center area much more larger for negative cases and the center area was smaller 
    for positive COVID cases. This could potentially related to the methods on how medical professionals 
    take COVID CT-Scans but it was one of the observations that we made through our clustering.</p>
  <h3>
<center><h5>COVID Negative DBSCAN Clustering</h5></center>
<center><img src="images/dbscan_negative.png" alt="DBSCANneg"></center>
<center><h5>COVID Positive DBSCAN Clustering</h5></center>
<center><img src="images/dbscan_positive.png" alt="DBSCANpos"></center>

<h3>
  <a id="GMM" class="anchor" href="#GMM" aria-hidden="true"><span aria-hidden="true" class="oction oction-link"></span></a>GMM</h3>
  <p>
    The results found from GMM has several implications towards further understanding what happens to a human
    lung when coming in contact with the Covid-19. In order to understand the findings from GMM, we must first
    discuss the capabilities and limitations of GMM in regards to clustering grayscale images.
  </p> 
    
  <p>
    In terms of capabilities, GMM has the ability to pick up ground glass opacity, which is abnormal findings on a
    CT scan which result in a hazy, obscured view of the underlying structure of the lungs. Because GMM can
    recognize these subtle changes, the algorithm bypasses the loss of information from this phenomenon, 
    allowing it to draw focus towards anomalies in the lungs. Now, we certainly are no medical experts, but the
    ability of the algorithm to filter out the "noise" associated with the CT scans certainly has positive implications
    in the medical field, not just in terms of Covid-19, but CT scans in general.
  </p>

  <p>
    With regards to limitations, GMM was not able to process multiple images at one time, which would be excellent for 
    classifying incoming CT scans. We had to run each image individually, one at a time. This was not only a time consuming
    process, but also provided the inability for the algorithm to prove it could correctly group negative scans against 
    positive scans, which would certainly prove beneficial for supervised learning. 
  </p>

  <p>
    Below are samples of images generated from the GMM algorithm. The images are labeled as either a Covid-19 negative patient
    or Covid-19 positive patient. The leftmost image is the original CT scan, the graph represents the bin clustering, indicating
    how many clusters may exist in the data. The rightmost image is the clustered, grayscale image generated by GMM. We can draw the 
    conclusion that, in general, the center between the lungs was bigger in Covid positive patients and smaller in Covid negative patients,
    which aligns with our findings from DBSCAN. Whether this is medically significant would be left up to the doctors, but it was consistant 
    across many images.
  </p>

<center><h5>COVID Negative GMM Clustering (Image 1)</h5></center>
<center><img src="images/gmm_neg1.png" alt="GMMneg1"></center>
<center><h5>COVID Negative GMM Clustering (Image 2)</h5></center>
<center><img src="images/gmm_neg2.png" alt="GMMneg2"></center>
<center><h5>COVID Positive GMM Clustering (Image 1)</h5></center>
<center><img src="images/gmm_pos1.png" alt="GMMpos1"></center>
<center><h5>COVID Positive GMM Clustering (Image 2)</h5></center>
<center><img src="images/gmm_pos2.png" alt="GMMpos2"></center>

<h2><a id="supervised" class="anchor" href="#supervised_learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Supervised Learning</h2>

<h3>
  <a id="cnn" class="anchor" href="#CNN" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Convolutional Neural Network</h3>
  <p>For the supervised portion, we decided to use convolutional neural networks in order to predict whether or not 
    someone has COVID based on a lung CT scan.</p>
  <p><b>Initial values:</b></p>
  <ul>
    <li>Data Cleaning</li>
      <ul>
        <li>Scaled from 0 to 255</li>
        <li>Random Shear of 0.2</li>
        <li>Random Zoom of 0.2</li>
      </ul>
    <li>Data Splitting</li>
      <ul>
        <li>70% training</li>
        <li>20% validation</li>
        <li>10% testing</li>
      </ul>
    <li>Model Structure</li>
      <center><h5>CNN Structure</h5></center>
      <center><img src="images/CNN.JPG" alt="CNN_structure"></center>
  </ul>
  <p>As you can see on our model structure, we have 3 sets of Conv2D and then max pooling, then the model flattens the 
    data. Then there’s 2 layers in the fully connected layers. The first layer uses relu activation function and the second 
    layer uses sigmoid activation function. We used an adam optimizer as well as a binary cross entropy loss function.<br>
    Before our touchpoint, we were able to achieve 84.36% accuracy as shown below:
  </p>
  <center><h5>First Accuracy Result</h5></center>
  <center><img src="images/bash1.JPG" alt="bash_1"></center>
  <p>Afterwards, in order to improve the accuracy of the model after the touchpoint and their feedback, we decided to 
    increase our shear to 0.25 and our zoom to 0.25 and achieved an accuracy of >90%:
  </p>
  <center><h5>Second Accuracy Result</h5></center>
  <center><img src="images/accuracy2.JPG" alt="acc_2"></center>
  <p>Introducing a random rotation of 15 degrees further improved our accuracy to 93.68%:
  </p>
  <center><h5>Third Accuracy Result</h5></center>
  <center><img src="images/accuracy3.JPG" alt="acc_3"></center>
  <p>We also attempted to use the ResNet50 architecture. Unfortunately, it did not work as we anticipated. Training took 
    a long time, and the model was quite inaccurate as well.
  </p>

  <h2><a id="conclusions" class="anchor" href="#conclusions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusions</h2>
  <p>Being able to achieve an accuracy of 93.68% has great implications in terms of being able to quickly identify COVID-19 
    for medical professionals and their patients. By using our model, the decision making process is cut down to mere seconds 
    and can further affirm a professional’s analysis of lung CT scans. In addition, as COVID-19 lung CT scan datasets begin 
    to diversify to severity and cross comparisons to other diseases, this project demonstrates that machine learning can be 
    applicable in identifying other respiratory diseases outside of COVID-19 and even differentiate between COVID-19 and other 
    diseases. Furthermore, our project also demonstrates the usefulness of unsupervised techniques on lung ct scans as well. 
    When running DBSCAN and GMM as ways to segment images, they both helped outline patterns that one can find between COVID-19 
    negative and positive images. The CAM unsupervised technique could also be essential as they show that neural networks seem 
    to respond to ground glass opacities. Both our unsupervised and supervised techniques could potentially aid medical 
    professionals in making better conclusions about lung CT scans overall. 
  </p>

<h3>
  <a id="references" class="anchor" href="#references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h3>
  <ul>
    <li><p><a href=
      "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6088146/">
      Description of pneumonia, and its impact on lungs
    </a></p></li>
    <li><p><a href=
      "https://www.hopkinsmedicine.org/health/conditions-and-diseases/coronavirus/what-coronavirus-does-to-the-lungs">
      Types of damages to lungs
    </a></p></li>
    <li><p><a href=
      "https://www.nejm.org/doi/full/10.1056/NEJMoa2015432">
      Extent of injury due to COVID-19 on the lungs
    </a></p></li>
    <li><p><a href=
      "https://www.kaggle.com/luisblanche/covidct?select=CT_NonCOVID">
      COVID-19 lung CT scan image dataset
    </a></p></li>
  </ul>

<p></p>
        </article>
      </div>
    </div>
    <footer>
      <div class="owner">
      <p><a href="https://github.gatech.edu/aazmi6" class="avatar"><img src="https://github.gatech.edu/avatars/u/30764?s=60" width="48" height="48"></a> <a href="https://github.gatech.edu/aazmi6">aazmi6</a> maintains <a href="https://github.gatech.edu/aazmi6/CS4641-Group39.github.io">Cs4641-group39.GitHub.io</a></p>


      </div>
      <div class="creds">
        <small>Find the code for our project at https://github.gatech.edu/ssubramanian87/Lung-COVID-Detection</small>
        <small>This page generated using <a href="https://pages.github.com/">GitHub Pages</a><br>theme by <a href="https://twitter.com/jonrohan/">Jon Rohan</a></small>
      </div>
    </footer>
  </div>
  <div class="current-section">
    <a href="#top">Scroll to top</a>
    <a href="https://github.gatech.edu/aazmi6/CS4641-Group39.github.io/tarball/master" class="tar">tar</a><a href="https://github.gatech.edu/aazmi6/CS4641-Group39.github.io/zipball/master" class="zip">zip</a><a href="" class="code">source code</a>
    <p class="name"></p>
  </div>

  
</body>
</html>
